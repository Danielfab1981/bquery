{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment:\n",
    "1. start dask scheduler\n",
    "   > dask-scheduler\n",
    "2. start dask-worker on HOST 1:\n",
    "   > dask-worker scheduler_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client\n",
    "from os.path import expanduser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following parameters\n",
    "DASK_SCHEDULER = \"192.168.1.109:8786\"\n",
    "PARQUET_DIRECTORY = os.path.join(expanduser(\"~\"), \"Documents/taxi/parquet_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(parquet_directory, columns):\n",
    "    \"\"\"\n",
    "    Load parquet files. The parquet directory should be present on the worker execution this task\n",
    "\n",
    "    \"\"\"\n",
    "    ddf = dd.concat([dd.read_parquet(f\"{parquet_directory}/{x}/*.parquet\", columns=columns, engine='pyarrow') for x in os.listdir(parquet_directory)])\n",
    "    return ddf\n",
    "\n",
    "def fn_count(ddf, columns):\n",
    "    \"\"\"\n",
    "    Count\n",
    "\n",
    "    \"\"\"\n",
    "    s = ddf[columns].count()\n",
    "    return s.compute()\n",
    "\n",
    "\n",
    "def fn_sum(ddf, columns):\n",
    "    \"\"\"\n",
    "    Sum\n",
    "\n",
    "    \"\"\"\n",
    "    s = ddf[columns].sum()\n",
    "    return s.compute()\n",
    "\n",
    "\n",
    "def fn_mean(ddf, columns):\n",
    "    \"\"\"\n",
    "    Mean\n",
    "\n",
    "    \"\"\"\n",
    "    s = ddf[columns].mean()\n",
    "    return s.compute()\n",
    "\n",
    "\n",
    "def fn_median(ddf, columns):\n",
    "    \"\"\"\n",
    "    Median\n",
    "\n",
    "    \"\"\"\n",
    "    s = ddf[columns].quantile(0.5)\n",
    "    return s.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tasks(task_list, columns, client, parquet_directory):\n",
    "    \"\"\"\n",
    "    Run the tasks\n",
    "    \n",
    "    \"\"\"\n",
    "    delayed_computation_list = list()\n",
    "    # create delayed tasks\n",
    "    ddf = delayed(load_data)(parquet_directory, columns)\n",
    "    for task in task_list:\n",
    "        delayed_computation = delayed(task)(ddf, columns)\n",
    "        delayed_computation_list.append(delayed_computation)\n",
    "    # run tasks on the cluster\n",
    "    future = client.compute(delayed_computation_list)\n",
    "    # wait for all the results\n",
    "    return client.gather(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 4.179220199584961s\n",
      "result: \n",
      "[nr_rides    25199507\n",
      "dtype: int64, nr_rides    25199507\n",
      "dtype: int64, nr_rides    1.0\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Create a Dask client and execute the tasks on the cluster\"\"\"\n",
    "    client = Client(DASK_SCHEDULER)\n",
    "    task_list = [fn_count, fn_sum, fn_mean]\n",
    "    t = time.time()\n",
    "    result_list = run_tasks(task_list, ['nr_rides'], client, PARQUET_DIRECTORY)\n",
    "    print(f\"duration: {time.time() - t}s\")\n",
    "    print(f\"result: \")\n",
    "    print(result_list)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
